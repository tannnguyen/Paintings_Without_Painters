{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#from PIL import Image\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torch.autograd import Variable\n",
    "from cnn_finetune import make_model\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PainterDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        #self.df = pd.read_csv(csv_file, usecols=['filename','artist']) #isolate painter and filename\n",
    "        self.df = pd.read_csv(csv_file, usecols=['file1','file2', 'label'])\n",
    "        #self.groups = self.df.groupby(['artist'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        os.chdir(self.img_dir)\n",
    "        row = self.df.iloc[[idx]]\n",
    "        filename_1 = row['file1'].item()\n",
    "        filename_2 = row['file2'].item()\n",
    "        label = row['label'].item()\n",
    "        \n",
    "        img_1 = io.imread(filename_1)\n",
    "        img_2 = io.imread(filename_2)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_1 = self.transform(img_1)\n",
    "            img_2 = self.transform(img_2)\n",
    "        \n",
    "        label = torch.tensor([label]) #1 if same, 0 if not\n",
    "        \n",
    "        return img_1, img_2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, cnn):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn = cnn\n",
    "        self.fc = nn.Sequential(\n",
    "                  nn.Linear(in_features = 65536, out_features = 4096, bias = True),\n",
    "                  nn.ReLU (inplace = True),\n",
    "                  nn.Dropout(p=0.5),\n",
    "                  nn.Linear(in_features = 4096, out_features = 4096,  bias = True),\n",
    "                  nn.ReLU (inplace = True),\n",
    "                  nn.Dropout(p=0.5),\n",
    "                  nn.Linear(in_features = 4096, out_features = 128, bias = True),\n",
    "                  nn.ReLU (inplace = True),\n",
    "                  nn.Dropout(p=0.5),\n",
    "                  nn.Linear(in_features = 128, out_features = 1, bias = True)\n",
    "                               )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        return output\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        output1 = self.forward_once(img1)\n",
    "        output2 = self.forward_once(img2)\n",
    "        features = torch.cat((output1, output2),1) # dimension: 3072 \n",
    "        features = self.fc(features)\n",
    "        return torch.sigmoid(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self, batch_size= 32 , test_batch_size= 16 ,\n",
    "            epochs=5, lr=0.01, momentum=0.5,\n",
    "            log_interval=100,seed=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = test_batch_size # Input batch size for testing\n",
    "        self.epochs = epochs # Number of epochs to train\n",
    "        self.lr = lr # Learning rate\n",
    "        self.momentum = momentum \n",
    "        self.log_interval = log_interval # Batches to wait before logging\n",
    "                                     # detailed status. 0 = never\n",
    "        self.seed = seed # Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(object):\n",
    "   \n",
    "    #train_csv = os.path.join(data_dir,'train1_pair.csv')    # adjust it to work on different folder\n",
    "    train_csv = os.path.join(data_dir,'train_120k_pair.csv')\n",
    "    train_dir = os.path.join(data_dir,'train_reg')\n",
    "    test_csv = os.path.join(data_dir,'test_pair.csv')\n",
    "    test_dir = os.path.join(data_dir,'test_reg')\n",
    "    \n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "    \n",
    "    transform1 = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    train_dataset = PainterDataset(csv_file = train_csv, img_dir = train_dir, transform = transform1)\n",
    "    test_dataset = PainterDataset(csv_file = test_csv, img_dir = test_dir, transform = transform1)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, epoch, total_minibatch_count, train_losses, train_accs):\n",
    "  \n",
    "    #training\n",
    "    model.train()\n",
    "    loss = nn.BCELoss()\n",
    "    correct_count, total_loss, total_acc = 0., 0., 0.\n",
    "    progress_bar = tqdm.tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for batch_idx, (input1, input2, target) in enumerate(progress_bar):\n",
    "        input1, input2, target = input1.cuda(), input2.cuda(), target.cuda()\n",
    "        input1, input2, target = Variable(input1), Variable(input2),Variable(target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward prediction step\n",
    "        output = model(input1, input2)\n",
    "        train_loss = loss(output,target.float())\n",
    "        \n",
    "        # Backpropagation step\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = (output > 0.5)\n",
    "\n",
    "        matches = (target.float() == pred.float())\n",
    "        accuracy = matches.float().mean()\n",
    "        correct_count += matches.sum()\n",
    "\n",
    "        if args.log_interval != 0 and \\\n",
    "                total_minibatch_count % args.log_interval == 0:\n",
    "\n",
    "            train_losses.append(train_loss.item())\n",
    "            train_accs.append(accuracy.data[0])\n",
    "            \n",
    "        total_loss += train_loss.data\n",
    "        total_acc += accuracy.data\n",
    "            \n",
    "        progress_bar.set_description(\n",
    "            'Epoch: {} loss: {:.4f}, acc: {:.2f}'.format(\n",
    "                epoch, total_loss / (batch_idx + 1), total_acc / (batch_idx + 1)))\n",
    "        #progress_bar.refresh()\n",
    "\n",
    "        total_minibatch_count += 1\n",
    "\n",
    "    return total_minibatch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "         #, epoch, total_minibatch_count,val_losses, val_accs):\n",
    "    \n",
    "    # testing\n",
    "    model.eval()\n",
    "    loss = nn.BCELoss()\n",
    "    test_loss, correct = 0., 0.\n",
    "    progress_bar = tqdm.tqdm(test_loader, desc='Validation')\n",
    "    with torch.no_grad():\n",
    "        for input1, input2, target in progress_bar:\n",
    "            input1, input2, target = input1.cuda(), input2.cuda(), target.cuda()\n",
    "            input1, input2, target = Variable(input1), Variable(input2), Variable(target)\n",
    "            \n",
    "            output = model(input1, input2)\n",
    "            test_loss += loss(output,target.float())\n",
    "            pred =  (output > 0.5)\n",
    "            correct += torch.sum(target.float() == pred.float())\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    #val_losses.append(test_loss)\n",
    "    #val_accs.append(acc)\n",
    "    \n",
    "    progress_bar.clear()\n",
    "    progress_bar.write(\n",
    "        'validation test results - Average val_loss: {:.4f}, val_acc: {}/{} ({:.2f}%)'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "      \n",
    "def run_experiment(args):\n",
    "\n",
    "    total_minibatch_count = 0\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "    '''\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "    '''\n",
    "    \n",
    "    train_loader, test_loader, = prepare_dataset(args)\n",
    "    epochs_to_run = args.epochs\n",
    "    cnn = models.vgg16(pretrained=True).features.eval() \n",
    "    #cnn = models.resnet18(pretrained=True).eval() \n",
    "    #cnn.fc = Identity()\n",
    "    #cnn = make_model('inceptionresnetv2', num_classes=2, pretrained=True)\n",
    "    #cnn._classifier = Identity()\n",
    "    for param in cnn.parameters():\n",
    "        param.requires_grad = False\n",
    "    model = SiameseNetwork(cnn).cuda()\n",
    "    #model = Siamese().cuda()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = args.lr, momentum = args.momentum)\n",
    "    #optimizer = optim.Adam(model.parameters())\n",
    "    val_acc = 0\n",
    "    train_losses, train_accs = [], []\n",
    "    #val_losses, val_accs = [], []\n",
    "\n",
    "    for epoch in range(1, epochs_to_run + 1):\n",
    "        \n",
    "        total_minibatch_count = train(model, optimizer, train_loader, epoch, total_minibatch_count, train_losses, train_accs)\n",
    "        test(model, test_loader)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "model = run_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, os.path.join('vgg.ph'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
