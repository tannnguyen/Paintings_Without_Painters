{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/morganthobson/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_extension(id, extension):\n",
    "    Image.EXTENSION[extension.lower()] = id.upper()\n",
    "Image.register_extension = register_extension\n",
    "\n",
    "def register_extensions(id, extensions):\n",
    "    for extension in extensions:\n",
    "        register_extension(id, extension)\n",
    "Image.register_extensions = register_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "      def __init__(self, batch_size=8, test_batch_size=16,\n",
    "            epochs=10, lr=0.01, momentum=0.5,\n",
    "            log_interval=100,seed=1,name='Alexnet'):\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = test_batch_size # Input batch size for testing\n",
    "        self.epochs = epochs # Number of epochs to train\n",
    "        self.lr = lr # Learning rate\n",
    "        self.momentum = momentum \n",
    "        self.log_interval = log_interval # Batches to wait before logging\n",
    "                                         # detailed status. 0 = never\n",
    "        self.seed = seed # Random seed\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify to read a pair in at a time. No longer generate a pair when coming in\n",
    "# Consistency for all the run\n",
    "class PainterDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.df = pd.read_csv(csv_file, usecols=['file1','file2', 'label'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        os.chdir(self.img_dir)\n",
    "        row = self.df.iloc[[idx]]\n",
    "        filename_1 = row['file1'].item()\n",
    "        filename_2 = row['file2'].item()\n",
    "        label = row['label'].item()\n",
    "        \n",
    "        img_1 = Image.open(filename_1)\n",
    "        img_2 = Image.open(filename_2)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_1 = self.transform(img_1)\n",
    "            img_2 = self.transform(img_2)\n",
    "        \n",
    "        label = torch.tensor([label]) #1 if same, 0 if not\n",
    "        \n",
    "        return img_1, img_2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['AlexNet', 'alexnet']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 7 * 7)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def alexnet(pretrained=False, **kwargs):\n",
    "    r\"\"\"AlexNet model architecture from the\n",
    "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = AlexNet(**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['alexnet']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, cnn):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn = cnn\n",
    "        self.fc = nn.Sequential(\n",
    "                  nn.Linear(in_features = 25088, out_features = 16384, bias = True),\n",
    "                  nn.ReLU (inplace = True),\n",
    "                  nn.Linear(in_features = 16384, out_features = 4096, bias = True),\n",
    "                  nn.ReLU (inplace = True),\n",
    "                  nn.Linear(in_features = 4096, out_features = 2048, bias = True),\n",
    "                  nn.ReLU (inplace = True),\n",
    "                  nn.Linear(in_features = 2048, out_features = 128, bias = True),\n",
    "                  nn.ReLU (inplace= True),\n",
    "                  nn.Linear (in_features = 128, out_features = 1, bias = True)\n",
    "                                )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        return output\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        output1 = self.forward_once(img1)\n",
    "        output2 = self.forward_once(img2)\n",
    "        features = torch.cat((output1, output2),1)\n",
    "        features = self.fc(features)\n",
    "        return torch.sigmoid(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(object):\n",
    "   \n",
    "    train_csv = os.path.join(data_dir,'train_120k_pair.csv')    # adjust it to work on different folder\n",
    "    train_dir = os.path.join(data_dir, 'train_reg')\n",
    "    test_csv = os.path.join(data_dir,'test_30k_pair.csv')\n",
    "    test_dir = os.path.join(data_dir,'test_reg')\n",
    "    \n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "    train_dataset = PainterDataset(csv_file = train_csv, img_dir = train_dir, transform = transforms.ToTensor())\n",
    "    test_dataset = PainterDataset(csv_file = test_csv, img_dir = test_dir, transform = transforms.ToTensor())\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, epoch, total_minibatch_count, train_losses, train_accs):\n",
    "  \n",
    "    #training\n",
    "    model.train()\n",
    "    loss = nn.BCELoss()\n",
    "    correct_count, total_loss, total_acc = 0., 0., 0.\n",
    "    progress_bar = tqdm.tqdm(train_loader, desc='Training')\n",
    "    \n",
    "    for batch_idx, (input1, input2, target) in enumerate(progress_bar):\n",
    "        input1, input2, target = input1.cuda(), input2.cuda(), target.cuda()\n",
    "        input1, input2, target = Variable(input1), Variable(input2),Variable(target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward prediction step\n",
    "        output = model(input1, input2)\n",
    "        train_loss = loss(output,target.float())\n",
    "        \n",
    "        # Backpropagation step\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = (output > 0.5)\n",
    "\n",
    "        matches = (target.float() == pred.float())\n",
    "        accuracy = matches.float().mean()\n",
    "        correct_count += matches.sum()\n",
    "\n",
    "        if args.log_interval != 0 and \\\n",
    "                total_minibatch_count % args.log_interval == 0:\n",
    "\n",
    "            train_losses.append(train_loss.item())\n",
    "            train_accs.append(accuracy.data[0])\n",
    "            \n",
    "        total_loss += train_loss.data\n",
    "        total_acc += accuracy.data\n",
    "            \n",
    "        progress_bar.set_description(\n",
    "            'Epoch: {} loss: {:.4f}, acc: {:.2f}'.format(\n",
    "                epoch, total_loss / (batch_idx + 1), total_acc / (batch_idx + 1)))\n",
    "        #progress_bar.refresh()\n",
    "\n",
    "        total_minibatch_count += 1\n",
    "\n",
    "    return total_minibatch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, epoch, total_minibatch_count,val_losses, val_accs):\n",
    "    \n",
    "    # testing\n",
    "    model.eval()\n",
    "    loss = nn.BCELoss()\n",
    "    test_loss, correct = 0., 0.\n",
    "    progress_bar = tqdm.tqdm(test_loader, desc='Validation')\n",
    "    with torch.no_grad():\n",
    "        for input1, input2, target in progress_bar:\n",
    "            \n",
    "            input1, input2, target = input1.cuda(), input2.cuda(), target.cuda()\n",
    "            input1, input2, target = Variable(input1), Variable(input2), Variable(target)\n",
    "            \n",
    "            output = model(input1, input2)\n",
    "            test_loss += loss(output,target.float())\n",
    "            pred =  (output > 0.5)\n",
    "            correct += torch.sum(target.float() == pred.float())\n",
    "\n",
    "    test_loss /= float(len(test_loader.dataset))\n",
    "    \n",
    "    acc = float(correct) / len(test_loader.dataset)\n",
    "\n",
    "    val_losses.append(test_loss)\n",
    "    val_accs.append(acc)\n",
    "    \n",
    "    progress_bar.clear()\n",
    "    progress_bar.write(\n",
    "        '\\nEpoch: {} validation test results - Average val_loss: {:.4f}, val_acc: {}/{} ({:.2f}%)'.format(\n",
    "            epoch, test_loss, correct, len(test_loader.dataset),\n",
    "            100. * float(correct) / len(test_loader.dataset)))\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(args):\n",
    "\n",
    "    total_minibatch_count = 0\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    \n",
    "    train_loader, test_loader, = prepare_dataset(args)\n",
    "    epochs_to_run = args.epochs\n",
    "    #cnn = alexnet(pretrained=False, num_classes=2048)\n",
    "    cnn = models.alexnet(pretrained=True).eval()\n",
    "    modules = list(cnn.children())[:-1]      # delete the last fc layer.\n",
    "    cnn = nn.Sequential(*modules)\n",
    "    for param in cnn.parameters():\n",
    "        param.requires_grad = True\n",
    "    model = SiameseNetwork(cnn).cuda()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = args.lr, momentum = args.momentum)\n",
    "    val_acc = 0\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "    \n",
    "    model.load_state_dict(torch.load('/home/morganthobson/Data/alexnet.pt'))\n",
    "\n",
    "    for epoch in range(1, epochs_to_run + 1):\n",
    "        \n",
    "        total_minibatch_count = train(model, optimizer, train_loader, epoch, total_minibatch_count, train_losses, train_accs)\n",
    "        val_acc = test(model, test_loader, epoch, total_minibatch_count, val_losses, val_accs)\n",
    "    \n",
    "    fig, axes = plt.subplots(1,4, figsize=(13,4))\n",
    "    # plot the losses and acc\n",
    "    plt.title(args.name)\n",
    "    axes[0].plot(train_losses)\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[1].plot(train_accs)\n",
    "    axes[1].set_title(\"Acc\")\n",
    "    axes[2].plot(val_losses)\n",
    "    axes[2].set_title(\"Val loss\")\n",
    "    axes[3].plot(val_accs)\n",
    "    axes[3].set_title(\"Val Acc\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "model = run_experiment(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), '/home/morganthobson/Data/alexnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
